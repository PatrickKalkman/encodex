# Convex Hull Computation for VMAF-Based Encoding Ladder Optimization

## 1. Understanding the Convex Hull of Bitrate–Quality–Resolution Data

 ([How Netflix Pioneered Per-Title Video Encoding Optimization - Streaming Learning Center](https://streaminglearningcenter.com/encoding/how-netflix-pioneered-per-title-video-encoding-optimization.html)) *Illustration of quality-vs-bitrate curves for low, mid, and high resolutions, with the red line showing the convex hull (Pareto-optimal frontier).* 

In video encoding, each resolution yields a **rate–quality curve**: as bitrate increases, quality (e.g. VMAF) improves, but eventually plateaus. Lower resolutions often outperform higher ones at low bitrates (since high-res encodes starve for bits), while high resolutions win out at high bitrates ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=At%20each%20resolution%2C%20the%20quality,get%20lost%20in%20the%20process)) ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=On%20the%20other%20hand%2C%20a,as%20blocking%2C%20ringing%20and%20contouring)). These curves typically *cross* – for example, 480p may give higher VMAF than 1080p at 500 kbps, but at 3000 kbps 1080p wins. The **convex hull** in this context is the *upper envelope* of all such rate–quality curves ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=We%20can%20see%20that%20each,the%20convex%20hull%20as%20possible)). In other words, it’s the set of encoding points that are **Pareto-optimal** – no other tested point offers *higher VMAF at an equal or lower bitrate* ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=We%20can%20see%20that%20each,the%20convex%20hull%20as%20possible)). Any encoding not on this hull is suboptimal (another point can surpass its quality at the same or lower bitrate). By operating on the convex hull, an encoding ladder achieves the best quality-for-bitrate efficiency ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=available%2C%20they%20collectively%20form%20a,the%20convex%20hull%20as%20possible)).

You can visualize the data in either 2D or 3D. In a 2D plot of VMAF vs. bitrate, each resolution’s encodes form a curve, and the convex hull appears as the *outermost* “curve” when considering all points together (as shown by the red line above). In a 3D plot (bitrate vs. resolution vs. VMAF), the convex hull corresponds to a surface connecting the optimal points on each resolution’s curve. In practice, it’s easiest to compute the hull by treating it as a 2D problem (bitrate-quality), using resolution only to label the points. The goal is to extract the set of (bitrate, resolution, VMAF) tuples that lie on this Pareto-efficient frontier.

**Extracting the convex hull:** A straightforward way is to plot all test encodes on a bitrate–VMAF graph and identify the outer boundary by inspection. Programmatically, we can determine it by scanning or using computational geometry:

- **Pareto scan method:** Sort all data points by increasing bitrate, then walk through them, tracking the highest VMAF seen so far. Any point that has a VMAF higher than all previous (lower-bitrate) points is on the upper hull. For example, if 480p @ 1000 kbps has higher VMAF than 720p @ 1000 kbps, the 480p point “dominates” at that bitrate. Once 720p (or 1080p) encodes catch up and exceed 480p’s quality, those higher-res points become the new frontier. By the end of the scan, you’ll have a list of points that steadily increase in VMAF as bitrate increases – these form the convex hull.

- **Convex hull algorithms:** We can also apply generic algorithms (Graham scan, Jarvis march, etc.) to the set of (bitrate, VMAF) points. Python’s **SciPy** library provides `scipy.spatial.ConvexHull`, which can compute the convex hull for a set of points in 2D or 3D ([ConvexHull — SciPy v1.15.2 Manual](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html#:~:text=ConvexHull%20%E2%80%94%20SciPy%20v1,1_00_00)). This yields a polygon enclosing all points – for rate–quality, we’re interested in the *upper* portion of that polygon. In practice, we filter hull vertices to keep those with the maximum quality for a given bitrate range.

Below is an example (in Python) of extracting the convex hull from a set of encodes using a simple scan. Each `encode` has a bitrate (in kbps), resolution, and VMAF:

```python
encodes = sorted(test_encodes, key=lambda e: e['bitrate'])  # sort by bitrate
convex_hull = []
max_vmaf_so_far = -float('inf')
for enc in encodes:
    b = enc['bitrate']; q = enc['vmaf']
    if q > max_vmaf_so_far:
        convex_hull.append(enc)
        max_vmaf_so_far = q

# convex_hull now contains the Pareto-optimal points in ascending bitrate order
for pt in convex_hull:
    print(f"{pt['resolution']} @ {pt['bitrate']} kbps -> VMAF {pt['vmaf']:.1f}")
```

This logic keeps any point that has a higher VMAF than all points at lower bitrates. The result is the list of encoding configurations that define the optimal **quality-vs-bitrate trade-off curve**. (If two points have identical VMAF or bitrate, you may want to include only the one with lower bitrate or higher VMAF, as appropriate.) In essence, for each relevant bitrate region, you select the resolution that yields the highest VMAF ([Formulate the Optimal Encoding Ladder with VMAF - Streaming Learning Center](https://streaminglearningcenter.com/encoding/optimal_encoding_ladder_vmaf.html#:~:text=file%20at%20different%20resolutions%20and,each%20rung%20in%20the%20ladder)).

**2D/3D visualization:** It’s often helpful to visualize the hull. Plotting each resolution’s VMAF curve and highlighting the hull can reveal the “switch points” where one resolution overtakes another in quality. For example, you might see 480p dominate up to ~1500 kbps, then 720p from ~1500–2500 kbps, and 1080p above that – the crossover bitrates are where the convex hull jumps from one resolution curve to the next. In a 3D plot, these hull points would form a ridge on the bitrate-resolution-quality surface. By extracting the convex hull, we effectively identify these crossover points and the optimal path through the bitrate–quality surface.

## 2. Methods to Find the Optimal VMAF–Bitrate–Resolution Frontier

There are a few strategies to obtain the convex hull (i.e., the optimal encoding ladder) for a given piece of content, each with pros and cons:

- **Brute-Force Exhaustive Search:** This is the original Netflix approach – encode the video at many resolutions and bitrates, then measure VMAF for each and find the hull ([Formulate the Optimal Encoding Ladder with VMAF - Streaming Learning Center](https://streaminglearningcenter.com/encoding/optimal_encoding_ladder_vmaf.html#:~:text=of%20rungs%20in%20the%20encoding,each%20rung%20in%20the%20ladder)). Essentially, you sample the entire space densely. For example, Netflix’s per-title encoding work involved “dozens of encodes of the same file at different resolutions and data rates to find the convex hull, which is where the encoding point achieves Pareto efficiency” ([Formulate the Optimal Encoding Ladder with VMAF - Streaming Learning Center](https://streaminglearningcenter.com/encoding/optimal_encoding_ladder_vmaf.html#:~:text=of%20rungs%20in%20the%20encoding,each%20rung%20in%20the%20ladder)). The upside is accuracy – you directly measure every candidate point, so you can find the true optimal curve. The downside is **compute cost**: exhaustive encoding is extremely slow and expensive. Netflix noted their method was ~20× more computationally costly than a fixed ladder ([Instant Per-Title Encoding | Mux](https://www.mux.com/blog/instant-per-title-encoding#:~:text=,1)). This brute-force approach is feasible for offline VOD content (especially at Netflix scale), but impractical for live streams or providers without massive encoding infrastructure. Still, it provides a ground-truth convex hull against which faster methods can be benchmarked.

- **“Hull Walking” / Iterative Search:** Instead of encoding every combination, an iterative strategy finds the hull by adaptive testing. The idea is to encode just enough points to discover where each resolution’s curve intersects the next. For instance, you might start with a few broad samples (low, mid, high bitrate for each resolution). If you see that at 500 kbps, 480p has higher VMAF than 720p, but at 1500 kbps 720p overtakes 480p, you’ve roughly identified an intersection. You could then refine around that boundary (e.g. encode 480p and 720p at 1000 kbps to pinpoint the switch). By “walking” along the frontier in this way, you skip encodes that are clearly off the optimal path. This approach requires some intelligence to decide the next test encode (e.g. binary search on bitrate until VMAF curves cross). It’s much less effort than brute force, but still involves multiple encodes per resolution. Essentially, you trade some encoding load for a big speedup, at the risk of missing the true hull if you’re not thorough. A variant of this is using domain knowledge: for example, Netflix observed that quality gains flatten out after a certain bitrate for each resolution ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=At%20each%20resolution%2C%20the%20quality,get%20lost%20in%20the%20process)), so they knew roughly where to stop increasing bitrate for a given resolution.

- **CRF/QP Guided Sampling:** Instead of targeting specific bitrates, this method uses encodes at fixed quality steps and lets the bitrate vary. For example, encode the video at each resolution with a range of constant quality settings (CRF or fixed QP values) – say CRF 18, 23, 28, 33, etc. Each encode gives you a (bitrate, VMAF) point. Because CRF (or QP) essentially controls output quality, this naturally produces a set of points spread along the quality curve for each resolution. Netflix’s approach actually did this: they chose a few QP values “such that they are one JND apart” (one *Just Noticeable Difference* in quality) ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=It%20is%20practically%20infeasible%20to,closest%20to%20the%20convex%20hull)), measured the resulting bitrates and qualities, and interpolated the rate–quality curves from those sample points ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=It%20is%20practically%20infeasible%20to,closest%20to%20the%20convex%20hull)). From the interpolated curves, they derive the convex hull ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=quantization%20parameters%20,closest%20to%20the%20convex%20hull)). The advantage here is you need far fewer encodes than brute force (maybe a half-dozen per resolution) while still mapping out a smooth curve. It leverages the codec’s rate-control to sweep through quality levels. The accuracy is high if you choose enough sample points (and interpolation handles the gaps). The slight downside is you must measure and interpolate – and if the content has irregular rate–quality behavior, interpolation might miss a kink. However, for most content the rate–distortion (RD) curves are concave and smooth, so a few key points suffice. This approach is a good compromise: **fewer test encodes** but still content-aware. Modern per-title encoding systems often use CRF-guided trials to approximate the hull quickly.

- **Machine Learning Prediction:** With enough training data, you can predict the convex hull without exhaustive encoding. The idea is to use **content features** (e.g. motion, texture complexity, maybe even a low-res preview encode) to predict the RD curves or directly predict the optimal ladder. Companies like Mux have taken this route: “We created a test set of tens of thousands of encodes in order to find the convex hull of quality, bitrate, and resolution. We then trained a series of neural networks on this dataset… When a new video comes in, it is analyzed by the model, and the right encoding ladder is output.” ([Instant Per-Title Encoding | Mux](https://www.mux.com/blog/instant-per-title-encoding#:~:text=We%20created%20a%20test%20set,right%20encoding%20ladder%20is%20output)) This ML-based approach can give near-instant recommendations once the model is trained. There are two broad flavors in research ([Convex Hull Prediction Methods for Bitrate Ladder Construction: Design, Evaluation, and Comparison](https://arxiv.org/html/2310.15163v3#:~:text=brute,methods%20utilizing%20handcrafted%20feature%20extraction)): (a) using handcrafted features (e.g. measuring motion vectors, spatial detail metrics, etc. as input to a model) and (b) using deep learning to directly analyze the video frames. In either case, the model is trained to output either the convex hull points or the next-best ladder settings ([Convex Hull Prediction Methods for Bitrate Ladder Construction: Design, Evaluation, and Comparison](https://arxiv.org/html/2310.15163v3#:~:text=brute,methods%20utilizing%20handcrafted%20feature%20extraction)). The major benefit is speed – you avoid per-title brute-force encodes entirely, making it viable for live or real-time use. It also automates expertise: the model “learns” from many examples what an optimal ladder looks like for various content types. The downsides: training requires a huge encoding dataset up front, and the model’s prediction has some error margin. If the content is very unusual (e.g. out-of-distribution for the model), the predicted hull might be slightly off, so one might still do a few sanity-check encodes. Nonetheless, ML prediction is **state-of-the-art** for per-title encoding at scale, since it cuts computation dramatically after the initial investment ([Convex Hull Prediction Methods for Bitrate Ladder Construction: Design, Evaluation, and Comparison](https://arxiv.org/html/2310.15163v3#:~:text=brute,methods%20utilizing%20handcrafted%20feature%20extraction)). Many recent papers benchmark different ML techniques (from linear models to deep CNNs and RNNs) for convex hull prediction ([Convex Hull Prediction Methods for Bitrate Ladder Construction: Design, Evaluation, and Comparison](https://arxiv.org/html/2310.15163v3#:~:text=To%20address%20these%20challenges%2C%20numerous,16%2C%2017%2C%2018%2C%2019%2C%2020)).

**Trade-offs:** In summary, a brute-force search guarantees finding the true convex hull for that content, at enormous computational cost. Smarter search (hull-walking or CRF sampling) finds an *approximate* hull with far fewer encodes – with careful implementation, it can be nearly as accurate as brute force (Netflix reported ~20% bitrate savings with per-title vs fixed ladder, and ~30% with per-*shot* optimization ([Instant Per-Title Encoding | Mux](https://www.mux.com/blog/instant-per-title-encoding#:~:text=resolution%20at%20each%20point%20in,or%201080p%20might%20look%20better)) ([Instant Per-Title Encoding | Mux](https://www.mux.com/blog/instant-per-title-encoding#:~:text=We%20created%20a%20test%20set,right%20encoding%20ladder%20is%20output)), showing the value of granularity). ML prediction shifts the heavy work to an offline training phase, yielding a fast per-title solution; its accuracy depends on training data and feature quality. In practice, many systems use a hybrid: e.g. do a quick analysis on the video (some low-res encodes or content metrics) and feed that into a model or heuristic to choose the ladder, possibly followed by a light refinement step. The **optimal path on the VMAF–bitrate–resolution surface** can thus be obtained by brute-force measurement or intelligently guessed by algorithms – the choice comes down to resources and required turnaround time. For a one-off high-stakes encode (like a Netflix original), brute force or heavy sampling may be fine; for a platform encoding thousands of videos, an ML or fast heuristic approach is necessary.

## 3. Tools and Libraries for Convex Hull Extraction and Ladder Optimization

Several tools can help compute the convex hull or assist in building an optimal encoding ladder, especially in Python:

- **Scientific Computing Libraries (Python):** The **SciPy** library’s spatial module provides a `ConvexHull` class that can compute the convex hull in *N*-dimensions ([ConvexHull — SciPy v1.15.2 Manual](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html#:~:text=ConvexHull%20%E2%80%94%20SciPy%20v1,1_00_00)). For example, you can feed it an array of points `[[bitrate, quality], ...]` and it will return the indices of the hull vertices. You would then filter those to get the upper hull (since the hull will include the lower boundary as well). SciPy uses the Qhull algorithm under the hood (a robust computational geometry library). For 2D data, this is often overkill – a simple sort-and-scan (as shown earlier) is enough – but SciPy’s implementation is convenient and fast even for hundreds of points. Another useful library is **Shapely** (for geometric operations), which can compute a polygon from points (via `shapely.geometry.MultiPoint(points).convex_hull`). This could be applied if you wanted to get a convex polygon surrounding your (bitrate, VMAF) points, then examine its upper edge.

- **Data Processing and Analysis:** Standard Python tools like **NumPy** and **pandas** are very handy for filtering out dominated points. For instance, you could load all your test encode results into a pandas DataFrame and use group-by operations to find the max VMAF at each bitrate, or use boolean indexing to drop points that are clearly inferior. There are also specialized algorithms for computing the **Pareto front** (since our problem is essentially a 2D Pareto optimization: minimize bitrate, maximize quality). In multi-objective optimization libraries (e.g. `pymoo` or `deap`), you’ll find Pareto-front extraction functions, though for this simple case implementing it directly is trivial.

- **Visualization Tools:** While not directly “extracting” the hull, plotting libraries help you confirm and fine-tune the results. **Matplotlib** can plot the RD curves and the chosen hull points; **Plotly** or **Bokeh** can even create interactive 3D plots to explore the bitrate-resolution-quality space. During development, visualizing the convex hull for a few sample videos is extremely useful to ensure your algorithm is picking sensible points. (For example, you might spot that two hull points are very close in bitrate, yielding ladder rungs too tight together – a sign you might drop one of them for a more even ladder.)

- **Video Quality Metrics Tools:** Since VMAF is our core metric, the primary “tool” needed is a way to compute VMAF for each test encode. Netflix’s open-source **VMAF** library is the gold standard – and it’s integrated into **FFmpeg**. In practice, your pipeline can use FFmpeg with the `libvmaf` filter to output VMAF scores for each encoded segment automatically. This is not for convex hull computation per se, but it’s how you get the data that feeds into the hull algorithm. The user’s system spec already includes *QualityMetricsCalculator* with FFmpeg+VMAF, so that step is handled. Just be aware that the accuracy of the convex hull depends on the reliability of the metric – VMAF is designed to correlate well with perceived quality, so optimizing for VMAF tends to improve visual quality as well ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=Encoding%20at%20high%20resolution%20at,as%20blocking%2C%20ringing%20and%20contouring)).

- **Open-Source Projects & Scripts:** The streaming community has produced scripts and tools to automate per-title ladder generation. For example, Eyevinn Technology’s team published a GitHub repository with scripts to generate an optimal ladder using VMAF analysis (as described in a 2021 blog post) ([Automating video analysis to cut your streaming bandwidth usage in half - DEV Community](https://dev.to/video/automating-video-analysis-to-cut-your-streaming-bandwidth-usage-in-half-5hk1#:~:text=Optimizing%20ABR,repository)). These tools typically orchestrate encoding jobs, run VMAF, and apply a convex hull algorithm to suggest an encoding ladder. While not “libraries” in the traditional sense, they can serve as reference implementations. Likewise, academic implementations from papers (if released) could be useful; e.g. an SVR or neural network model to predict the hull given input features (some research code is often on GitHub or as supplementary material).

In summary, to *extract* the convex hull from data, you’ll rely on general-purpose numeric libraries (for computing or filtering points) – SciPy for an out-of the-box hull computation, or just Python logic for Pareto sorting. To *identify the optimal ladder*, you combine that with domain-specific constraints (discussed next) using simple code or existing scripts. And of course, the fundamental “tools” enabling this are the encoding and VMAF measurement tools that produce the data in the first place (FFmpeg, encoders, VMAF library).

## 4. Integrating Convex-Hull Logic into the RecommendationEngine

In the provided system, the **RecommendationEngine** is the stage that takes all the measured quality metrics and content analysis, and outputs final encoding parameters. Here’s how the convex-hull computation fits into that stage:

**Input to RecommendationEngine:** By this point, the pipeline has produced a set of *test encodes* (via the TestEncodingGenerator) for representative video segments, and the QualityMetricsCalculator has computed VMAF (and perhaps PSNR) for each. These results might be stored in a structure like `state['quality_metrics']`, which could be a list of records, e.g.:

```json
[
  {"resolution": "1920x1080", "bitrate": 5000, "vmaf": 96.5},
  {"resolution": "1280x720", "bitrate": 5000, "vmaf": 92.1},
  {"resolution": "1280x720", "bitrate": 2000, "vmaf": 86.9},
  {"resolution": "854x480", "bitrate": 2000, "vmaf": 84.3},
  ...
]
```

Each entry represents a test encode of a segment (or a composite of segments) at a certain resolution and bitrate, with the resulting VMAF. The RecommendationEngine needs to analyze this collection and pick out the *optimal set of (resolution, bitrate)* pairs to form the adaptive ladder.

**Convex hull computation:** Using the methods from section 1, the engine should compute the convex hull of the bitrate–VMAF points. In code, we could do:

```python
import numpy as np
from scipy.spatial import ConvexHull

# Assume quality_metrics is a list of dicts as above
points = np.array([(m["bitrate"], m["vmaf"]) for m in quality_metrics])
hull = ConvexHull(points)  # compute 2D convex hull

hull_indices = hull.vertices  # indices of points on the hull (unsorted)
hull_points = [quality_metrics[i] for i in hull_indices]

# Filter to upper hull (Pareto frontier) and sort by bitrate
hull_points.sort(key=lambda x: x["bitrate"])
pareto_front = []
max_vmaf = -1
for pt in hull_points:
    if pt["vmaf"] >= max_vmaf:
        pareto_front.append(pt)
        max_vmaf = pt["vmaf"]
```

After this, `pareto_front` will be a list of encoding configs that lie on or near the convex hull (from lowest to highest bitrate). Each entry has the resolution that gave the highest VMAF for that bitrate range. This is effectively the **initial recommended ladder**. We’d then integrate any business rules or practical constraints:

- Typically, the top rung is chosen at the highest resolution with a target high quality (often ~95 VMAF) ([Crafting the Ideal Encoding Ladder in Two Simple Steps - Streaming Learning Center](https://streaminglearningcenter.com/encoding/crafting-the-ideal-encoding-ladder-in-two-simple-steps.html#:~:text=Figure%201%20represents%20the%20data,highest%20quality%20at%20that%20bitrate)). In our hull approach, the highest tested bitrate at the source resolution (or one step below if we cap quality) will be the top point. For example, if 1080p @ 5 Mbps yields VMAF 96 and is on the hull, that’s a great top rung (since we often don’t stream beyond perceptual lossless quality). If our hull suggests an even higher bitrate for marginal gain (e.g. 1080p @ 8 Mbps for VMAF 98), we might voluntarily cap it to avoid diminishing returns, but that depends on company policy.

- We also ensure the ladder is *monotonic*: as we go down rungs, bitrate and resolution decrease. The convex hull guarantees the VMAF is lower for the next point, but it might sometimes pick two points of the same resolution in a row (if, say, 1080p had two hull segments). In practice, we might merge or skip such points for simplicity. Many systems enforce that each resolution appears at most once in the final ladder (since switching resolution up and down frequently is undesirable). In our case, the hull method naturally tends to one optimal resolution per “region” of the curve. For example, you might get something like: 1080p @ 4500 kbps (VMAF ~95), 720p @ 1500 kbps (VMAF ~84), 480p @ 600 kbps (VMAF ~75), etc. – each of those is the best quality you can get at that bitrate. These would be our ladder rungs.

- **Spacing and adjustments:** Pure convex-hull output might have rungs that are too close or too far in bitrate. It’s common to enforce that each successive bitrate is about 1.5–2× the previous (to ensure distinct quality steps and to accommodate ABR switching) ([Automating video analysis to cut your streaming bandwidth usage in half - DEV Community](https://dev.to/video/automating-video-analysis-to-cut-your-streaming-bandwidth-usage-in-half-5hk1#:~:text=1,a%20VMAF%20score%20above%2093)). If the hull gave two adjacent points at 2000 and 2300 kbps, we might decide to drop one because they’re too close. Conversely, if the hull jumps from 300 kbps to 1200 kbps, we might insert an intermediate rung (even if it’s slightly below the true hull) to fill the gap for smoother adaptation. These decisions involve slight trade-offs – you’re allowed to pick a point *close* to the convex hull if it significantly improves the ladder structure ([Automating video analysis to cut your streaming bandwidth usage in half - DEV Community](https://dev.to/video/automating-video-analysis-to-cut-your-streaming-bandwidth-usage-in-half-5hk1#:~:text=However%2C%20simply%20selecting%20the%20,to%20determine%20the%20final%20ladder)). The user’s spec indeed mentions focusing on hull efficiency rather than fixed VMAF thresholds, but still needing to determine final ladder rungs with some manual logic ([Automating video analysis to cut your streaming bandwidth usage in half - DEV Community](https://dev.to/video/automating-video-analysis-to-cut-your-streaming-bandwidth-usage-in-half-5hk1#:~:text=We%20can%20imagine%20a%20convex,at%20Pareto%20efficiency%2C%20as%20they)) ([Automating video analysis to cut your streaming bandwidth usage in half - DEV Community](https://dev.to/video/automating-video-analysis-to-cut-your-streaming-bandwidth-usage-in-half-5hk1#:~:text=However%2C%20simply%20selecting%20the%20,to%20determine%20the%20final%20ladder)). In an automated system, you can codify these rules.

**Integration example:** Suppose our `pareto_front` came out to (in human terms): 
- 1080p @ 5 Mbps (VMAF ~96) 
- 720p @ 2 Mbps (VMAF ~87) 
- 480p @ 0.7 Mbps (VMAF ~76) 
- 360p @ 0.3 Mbps (VMAF ~64)

We would package these as the recommended ladder. The RecommendationEngine might create a data structure like:

```python
ladder = []
for pt in pareto_front:
    res = pt["resolution"]
    br = pt["bitrate"]
    ladder.append({
        "resolution": res,
        "bitrate": f"{br}k",      # format as string with 'k'
        "profile": select_profile(res)  # e.g., High for HD, Main for SD etc.
    })
state["encoding_recommendations"] = ladder
```

Here, `select_profile(res)` is a placeholder for choosing H.264/H.265 profile or encoding preset based on resolution – not directly related to the hull, but important for output. (Often, higher resolutions use High profile, lower use Main or Baseline, as in the user’s example output.) The engine would also likely record the expected VMAF of each rung for reference, or at least ensure the top rung hits the desired quality target (say, “>=95 VMAF on top rung” as a rule).

Finally, the **OutputGenerator** would format this into JSON, include any analysis (like estimated savings vs. the old ladder), etc. The key point is that the RecommendationEngine’s logic after getting the convex hull is straightforward: **use those hull points as the ladder**, possibly trimming or adding points for smooth gradation. The result is a content-optimized set of encoding parameters. Crucially, because this ladder was derived from the convex hull of VMAF-vs-bitrate data, each rung should be operating near maximum efficiency (no wasted bitrate for the quality level) ([Per-Title Encode Optimization. delivering the same or better… | by Netflix Technology Blog | Netflix TechBlog](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html#:~:text=available%2C%20they%20collectively%20form%20a,the%20convex%20hull%20as%20possible)). In other words, we’ve used VMAF as the guiding metric to ensure every selected encoding is “as good as it gets” for that bitrate range. This approach directly addresses the user’s goal of **optimizing bitrate allocation based on content complexity** – complex content will simply have its hull points at higher bitrates for a given quality, while easy content will have high VMAF even at lower bitrates, and the recommended ladder will reflect that quantitatively.

**Implementation-ready summary:** The main integration steps in code are: 

1. Gather `quality_metrics` from the state (after test encodes).
2. Compute the convex hull (Pareto front) of those points (using either a custom function or SciPy as shown).
3. Sort and refine those points into the final ladder list.
4. Save the ladder to `state['encoding_recommendations']`.

By modularizing the convex hull computation (e.g., a function `compute_convex_hull(points)` that returns the Pareto-optimal subset), this logic can be cleanly inserted into the RecommendationEngine node of the LangGraph. Every time a new video is processed, the engine will receive a tailored set of hull points and output a JSON encoding ladder that is content-specific and VMAF-optimized.
